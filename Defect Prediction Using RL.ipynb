{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5s4zPTjTboAV",
    "outputId": "fdddf1c6-d364-4b6d-a798-97f728ceba44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kw2F4WKY1AKJ",
    "outputId": "e4629da3-521b-48a9-c01f-52062f4faebf"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFHl5n0BWljT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K159pS-P6yeI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "# tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "# for later versions:\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAk_bATDsWua"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras.initializers import RandomUniform\n",
    "\n",
    "from time import sleep,time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gym\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOItfAX0tnI5"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XV_hqQ79sWp9"
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self , dataset_name = 'merged - bug predict.csv' , minority_class = 1 , lambd = 0.9 , test_size = 0.2):\n",
    "        self.X,self.y ,self.X_test,self.y_test = self.load_data(dataset_name , test_size)\n",
    "        self.observation_space = self.X.shape[1]\n",
    "        self.action_space = 2\n",
    "        self.terminal = False\n",
    "        self.minority_class = minority_class\n",
    "        self.lambd = lambd\n",
    "        self.number_of_examples = self.X.shape[0]\n",
    "\n",
    "    def load_data(self , dataset_name , test_size):\n",
    "        data = pd.read_csv(dataset_name).dropna()\n",
    "        X = MinMaxScaler().fit_transform(data.values[:,1:-1])\n",
    "        y = data.values[:,-1].astype(int)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "        return X_train,y_train,X_test,y_test\n",
    "\n",
    "    def reset(self):\n",
    "        self.X, self.y = shuffle(self.X, self.y)\n",
    "        self.terminal = False\n",
    "\n",
    "    def step(self , action ,label):\n",
    "        reward = 0\n",
    "        if label == self.minority_class:\n",
    "            if action == label:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1\n",
    "                self.terminal = True\n",
    "        else:\n",
    "            if action == label:\n",
    "                reward = self.lambd\n",
    "            else:\n",
    "                reward = -self.lambd\n",
    "        return reward , self.terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "QjPq56U9sWhC",
    "outputId": "adc6668b-f3f5-4c94-d2bc-a376ca34ddca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sayam/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 1,178\n",
      "Trainable params: 1,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env = Environment()\n",
    "inputCount = env.observation_space\n",
    "actionsCount = env.action_space\n",
    "\n",
    "# Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=inputCount, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(actionsCount, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(), metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "#Initialize Memory And Epsilon\n",
    "memory = ([],[],[],[],[])\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MhygBkqvjlX"
   },
   "outputs": [],
   "source": [
    "def score(env , model , print_only = \"\"):\n",
    "    X_train = env.X\n",
    "    y_train = env.y\n",
    "    X_test = env.X_test\n",
    "    y_test = env.y_test\n",
    "    train_pred = model.predict(X_train.reshape((X_train.shape[0],X_train.shape[1])))\n",
    "    test_pred = model.predict(X_test.reshape((X_test.shape[0],X_train.shape[1])))\n",
    "    train_pred = np.argmax(train_pred , axis = 1)\n",
    "    test_pred = np.argmax(test_pred , axis = 1)\n",
    "    if print_only != \"AUC\":\n",
    "        print(\"On Training Data\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_train,train_pred))\n",
    "        TP = sum((y_train==train_pred)*y_train)\n",
    "        TN = sum((y_train==train_pred)*(1-y_train))\n",
    "        FN = sum((y_train!=train_pred)*y_train)\n",
    "        FP = sum((y_train!=train_pred)*(1-y_train))\n",
    "        # print(TP,TN,FN,FP)\n",
    "        acc = (TP+TN)/(TP+TN+FN+FP + np.finfo(float).eps)\n",
    "        prec =  TP/(TP+FP + np.finfo(float).eps)\n",
    "        rec = TP/(TP+FN + np.finfo(float).eps)\n",
    "        FPR = FP/(FP+TN + np.finfo(float).eps)\n",
    "        TNR = 1 - FPR\n",
    "        AUC = (rec+TNR)/2\n",
    "        print(\"Accuracy = \", acc)\n",
    "        print(\"Precision = \", prec)\n",
    "        print(\"Recall = \", rec)\n",
    "        print(\"F1 Score = \", 2*prec*rec/(prec+rec + np.finfo(float).eps))\n",
    "        print(\"AUC = \",AUC)\n",
    "        print()\n",
    "        print(\"On Testing Data\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test,test_pred))\n",
    "        TP = sum((y_test==test_pred)*y_test)\n",
    "        TN = sum((y_test==test_pred)*(1-y_test))\n",
    "        FN = sum((y_test!=test_pred)*y_test)\n",
    "        FP = sum((y_test!=test_pred)*(1-y_test))\n",
    "        # print(TP,TN,FN,FP)\n",
    "        acc = (TP+TN)/(TP+TN+FN+FP + np.finfo(float).eps)\n",
    "        prec =  TP/(TP+FP + np.finfo(float).eps)\n",
    "        rec = TP/(TP+FN + np.finfo(float).eps)\n",
    "        FPR = FP/(FP+TN + np.finfo(float).eps)\n",
    "        TNR = 1 - FPR\n",
    "        AUC = (rec+TNR)/2\n",
    "        print(\"Accuracy = \", acc)\n",
    "        print(\"Precision = \", prec)\n",
    "        print(\"Recall = \", rec)\n",
    "        print(\"F1 Score = \", 2*prec*rec/(prec+rec + np.finfo(float).eps))\n",
    "        print(\"AUC = \",AUC)\n",
    "    else:\n",
    "        print(\"On Training Data\" , end = \"\\t\")\n",
    "        TP = sum((y_train==train_pred)*y_train)\n",
    "        TN = sum((y_train==train_pred)*(1-y_train))\n",
    "        FN = sum((y_train!=train_pred)*y_train)\n",
    "        FP = sum((y_train!=train_pred)*(1-y_train))\n",
    "        acc = (TP+TN)/(TP+TN+FN+FP + np.finfo(float).eps)\n",
    "        prec =  TP/(TP+FP + np.finfo(float).eps)\n",
    "        rec = TP/(TP+FN + np.finfo(float).eps)\n",
    "        FPR = FP/(FP+TN + np.finfo(float).eps)\n",
    "        TNR = 1 - FPR\n",
    "        AUC = (rec+TNR)/2\n",
    "        print(\"Recall = \", rec , end  = \"\\t\")\n",
    "        print(\"AUC = \",AUC)\n",
    "        print(\"On Testing Data \" , end = \"\\t\")\n",
    "        TP = sum((y_test==test_pred)*y_test)\n",
    "        TN = sum((y_test==test_pred)*(1-y_test))\n",
    "        FN = sum((y_test!=test_pred)*y_test)\n",
    "        FP = sum((y_test!=test_pred)*(1-y_test))\n",
    "        # print(TP,TN,FN,FP)\n",
    "        acc = (TP+TN)/(TP+TN+FN+FP + np.finfo(float).eps)\n",
    "        prec =  TP/(TP+FP + np.finfo(float).eps)\n",
    "        rec = TP/(TP+FN + np.finfo(float).eps)\n",
    "        FPR = FP/(FP+TN + np.finfo(float).eps)\n",
    "        TNR = 1 - FPR\n",
    "        AUC = (rec+TNR)/2\n",
    "        print(\"Recall = \", rec , end = \"\\t\")\n",
    "        print(\"AUC = \",AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNcAVPJP8kk-"
   },
   "outputs": [],
   "source": [
    "def replay_memory(model , memory , batch_size = 64 , gamma = 1.0 , actionsCount = 2 , epochs = 1 , verbose = 0):\n",
    "    rand_nums = np.random.randint(0, len(memory), size=batch_size)\n",
    "    states = memory[0][rand_nums]\n",
    "    action = memory[1][rand_nums]\n",
    "    rewards = memory[2][rand_nums]\n",
    "    next_states = memory[3][rand_nums]\n",
    "    done = memory[4][rand_nums].astype(int)\n",
    "\n",
    "    target = rewards + (gamma * np.multiply((done+1)%2 , np.max(model.predict(next_states) , axis = 1)))\n",
    "    target_f = []\n",
    "    if gamma == 0:\n",
    "        target_f = np.zeros((batch_size , actionsCount))\n",
    "    if gamma != 0:\n",
    "        target_f = model.predict(states)\n",
    "    for i in range(actionsCount):\n",
    "        ind = np.where(action == i)\n",
    "        target_f[ind,i] = target[ind]\n",
    "    targets = target_f\n",
    "\n",
    "    model.fit(states, targets, epochs=epochs, verbose=verbose)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx-inNTJtJ9X"
   },
   "outputs": [],
   "source": [
    "def dqn_train(env , model , episodes = 5000 , gamma = 1.0 ,epsilon = 1.0 , epsilonMin = 0.01 , epsilonDecay = 0.999 , memory = ([],[],[],[],[]) ,batch_size = 64 , memoryMax = 500000 , resume_training = False , model_filename = None , save_model_filename = \"weights.h5\"):\n",
    "    if resume_training:\n",
    "        model.load_weights(model_filename)\n",
    "    inputCount = env.observation_space\n",
    "    actionsCount = env.action_space\n",
    "    \n",
    "    # Training\n",
    "    all_scores = []\n",
    "    l_states = memory[0]\n",
    "    l_actions = memory[1]\n",
    "    l_rewards = memory[2]\n",
    "    l_next_states = memory[3]\n",
    "    l_done = memory[4]\n",
    "\n",
    "    for e in tqdm(range(episodes)):\n",
    "        env.reset()\n",
    "        s = np.expand_dims(env.X[0],axis = 0)\n",
    "        l = env.y[0]\n",
    "        done = False\n",
    "        for ind in range(1 , env.number_of_examples - 1):\n",
    "            # Act greedy sometimes\n",
    "            if np.random.rand() <= epsilon:\n",
    "                a = random.randrange(actionsCount)\n",
    "            else:\n",
    "                a = np.argmax(model.predict(s))\n",
    "\n",
    "            r, done = env.step(a , l)\n",
    "            \n",
    "            newS = np.expand_dims(env.X[ind] , axis = 0)\n",
    "\n",
    "            if len(l_states) == 0:\n",
    "                l_states = s\n",
    "                l_actions = [a]\n",
    "                l_rewards = [r]\n",
    "                l_next_states = newS\n",
    "                l_done = [done]\n",
    "            else:\n",
    "                l_states = np.append(l_states , s , axis = 0)\n",
    "                l_actions = np.append(l_actions , [a] , axis = 0)\n",
    "                l_rewards = np.append(l_rewards , [r] , axis = 0)\n",
    "                l_next_states = np.append(l_next_states , newS , axis = 0)\n",
    "                l_done = np.append(l_done , [done] , axis = 0)\n",
    "\n",
    "            # free first items in memory\n",
    "            if len(l_states)>=memoryMax:\n",
    "                l_states = l_states[5000:]\n",
    "                l_actions = l_actions[5000:]\n",
    "                l_rewards = l_rewards[5000:]\n",
    "                l_next_states = l_next_states[5000:]\n",
    "                l_done = l_done[5000:]\n",
    "\n",
    "            if done:\n",
    "                # print(\"\\repisode: {}/{}, score: {}\".format(e, episodes, ind) , end = \"\")\n",
    "                # sys.stdout.flush()\n",
    "                all_scores.append(ind)\n",
    "                break\n",
    "\n",
    "            # State\n",
    "            s = np.expand_dims(env.X[ind] , axis = 0)\n",
    "            l = env.y[ind]\n",
    "\n",
    "        memory = (l_states , l_actions , l_rewards , l_next_states , l_done)\n",
    "\n",
    "        if epsilon > epsilonMin:\n",
    "            epsilon *= epsilonDecay\n",
    "\n",
    "        # Replay memory\n",
    "        if len(l_states) > batch_size:\n",
    "            model = replay_memory(model , memory , batch_size = batch_size , gamma = gamma , actionsCount = actionsCount , epochs = 1 , verbose = 0)\n",
    "\n",
    "        if (e+1)%200 == 0:\n",
    "            print(\"\\n\")\n",
    "            print(\"-\"*40 , e+1 , \"-\"*40)\n",
    "            score(env , model , print_only = \"AUC\")\n",
    "            print(\"-\"*42 , \"-\"*42)\n",
    "\n",
    "    print()\n",
    "    print(np.average(all_scores))\n",
    "\n",
    "    # Save weights\n",
    "    model.save_weights(save_model_filename)\n",
    "\n",
    "    return model,memory,epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "yZX2yywgy_AZ",
    "outputId": "bfdfcfa1-27b9-4554-a1a0-627cf28f3ac4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [00:00<00:24, 38.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sayam/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [00:07<00:42, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------- 200 ----------------------------------------\n",
      "On Training Data\tRecall =  0.936837975676736\tAUC =  0.6127159132307567\n",
      "On Testing Data \tRecall =  0.9320695102685624\tAUC =  0.6109015936222537\n",
      "------------------------------------------ ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [00:17<00:43, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------- 400 ----------------------------------------\n",
      "On Training Data\tRecall =  0.9356610435464888\tAUC =  0.6123424546908965\n",
      "On Testing Data \tRecall =  0.933649289099526\tAUC =  0.6116914830377356\n",
      "------------------------------------------ ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [00:31<00:34, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------- 600 ----------------------------------------\n",
      "On Training Data\tRecall =  0.9301686936053354\tAUC =  0.616530272410064\n",
      "On Testing Data \tRecall =  0.9289099526066351\tAUC =  0.6158725020765135\n",
      "------------------------------------------ ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [00:51<00:36,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------- 800 ----------------------------------------\n",
      "On Training Data\tRecall =  0.9466457434287956\tAUC =  0.6103095412478314\n",
      "On Testing Data \tRecall =  0.9399684044233807\tAUC =  0.6077634118336834\n",
      "------------------------------------------ ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:14<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------- 1000 ----------------------------------------\n",
      "On Training Data\tRecall =  0.945076500588466\tAUC =  0.6110837243858263\n",
      "On Testing Data \tRecall =  0.9399684044233807\tAUC =  0.6087299066790444\n",
      "------------------------------------------ ------------------------------------------\n",
      "\n",
      "25.912\n"
     ]
    }
   ],
   "source": [
    "model , memory , epsilon = dqn_train(env = env , model = model , memory = memory , epsilon = epsilon , memoryMax = 50000 , batch_size = 1024, episodes = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "8Dg38QdYzGTV",
    "outputId": "216507a8-09c2-4d24-ebc5-570e933f2da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Data\n",
      "Confusion Matrix:\n",
      "[[ 5155 13449]\n",
      " [  140  2409]]\n",
      "Accuracy =  0.35758521249940906\n",
      "Precision =  0.15191070752932273\n",
      "Recall =  0.945076500588466\n",
      "F1 Score =  0.26174824794914975\n",
      "AUC =  0.6110837243858263\n",
      "\n",
      "On Testing Data\n",
      "Confusion Matrix:\n",
      "[[1292 3364]\n",
      " [  38  595]]\n",
      "Accuracy =  0.35677821894498013\n",
      "Precision =  0.15029047739328114\n",
      "Recall =  0.9399684044233807\n",
      "F1 Score =  0.2591463414634146\n",
      "AUC =  0.6087299066790444\n"
     ]
    }
   ],
   "source": [
    "score(env , model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CibU8_Iz-0Th"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "all_ bug - RL_for_imbalanced.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}